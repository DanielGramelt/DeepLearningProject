{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Workpackage: Data engineering\n",
    "\n",
    "Research Question:\n",
    "**\"How far can we simplify the input data to be still able to distinguish between Hand, Paper, and Scissors?\"**\n",
    "\n",
    "Research Answer:\n",
    "We can simplify input pictures through by converting them to greyscale and reducing the resolution. Both methods can be used without loosing much of the needed elements. Additionaly we can blur the images, to remove details and only get rough shapes and then use segmentation methods like otsu to get a binary image with the shape of the hand. On simple and clear input images, this can work so good, that with the calculation of histograms one could distinguish the gestures without maschine learning at all. The drawbacks are, that one relies heavily on the selection of the segmentation method and thus needs to be carefully chosen. Another problem shows the segmentation of more complex data. There the segmentation with basic methods have shown to be very incorrect and partwise not usefull at all. But this could also be due to the fact that the implemented otsu method is a global threshold segmentation method, which is not siuted for this usecase. If one has a good segmentation method for this use case, one could as also implemented cut the background out, so that the ML algorithm just has to distinguish between face and hand if the segmentation method lacks of that capability.\n",
    "**All in all the simplest robust image we were able to generate, which could optimize the training robustly is the blurred greyscale image, which has a reduced resolution. Further evaluation needs to be done if the blurring really benefits the training.**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from skimage.filters import threshold_multiotsu\n",
    "\n",
    "def multi_otsu(output_path, img):\n",
    "    matplotlib.rcParams['font.size'] = 9\n",
    "    image = np.asarray(img)\n",
    "    thresholds = threshold_multiotsu(image)\n",
    "    regions = np.digitize(image, bins=thresholds)\n",
    "    plt.imshow(regions, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(output_path, bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "\n",
    "def process_file(filename, dir, output_dir):\n",
    "    path = os.path.join(dir, filename)\n",
    "    image = Image.open(path).convert('L')\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    multi_otsu(output_path, image)\n",
    "\n",
    "def main():\n",
    "    dir = '../Dataset/validation_set/scissors'\n",
    "    output_dir = '../Dataset/validation_otsu/scissors'\n",
    "    filenames = [filename for filename in os.listdir(dir) if filename.endswith(\".png\")]\n",
    "\n",
    "    with multiprocessing.Pool(processes=multiprocessing.cpu_count()) as pool:\n",
    "        pool.starmap(process_file, [(filename, dir, output_dir) for filename in filenames])\n",
    "\n",
    "main()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Workpackage: Model Engineering\n",
    "\n",
    "Research Question:\n",
    "**Can we get a more robust system by splitting the image recognition into more specific subtasks? i.e. using transfer learing**\n",
    "\n",
    "Research Answer:\n",
    "The motivation/reason behind using transfer learning is, that we noticed that the training dataset matches neither our validation dataset nor our custom dataset, which results in a bad performance. Problem is that the validation and test dataset are very divers, while our training dataset consists of many very similar photos. We concluded that either we create our own training dataset, which will be time consuming and runs into the problem, that the unknown training dataset will be different again and thus running in a similar problem. The approach to solve that problem is to use a pretrained model that can segment hands from everything else in the background and by that making the pictures in the different datasets more similar to each other. By that in our hypothesis the performance shall improve noticably. Unfortunatly we ran out of time finding such a pretrained model. The ones we found did not hold what they promised and were not robust at all, and others would we need to train ourselfes, which would require days and lots of energy.\n",
    "**In summary we tried using transfer learning to improve the performance, but were stopped because we could not find a suiting pretrained model.**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import multiprocessing\n",
    "import keras\n",
    "from PIL import Image\n",
    "\n",
    "def load_images(train_path, val_path):\n",
    "\n",
    "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        train_path,\n",
    "        validation_split=None,\n",
    "        subset=None,\n",
    "        seed=SEED,\n",
    "        shuffle=True,\n",
    "        color_mode='grayscale',\n",
    "        image_size=IMAGE_SHAPE,\n",
    "        batch_size=BATCH_SIZE)\n",
    "\n",
    "    val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        val_path,\n",
    "        validation_split=None,\n",
    "        subset=None,\n",
    "        seed=SEED,\n",
    "        shuffle=True,\n",
    "        color_mode='grayscale',\n",
    "        image_size=IMAGE_SHAPE,\n",
    "        batch_size=BATCH_SIZE)\n",
    "\n",
    "    class_names = train_ds.class_names\n",
    "    print(class_names)\n",
    "    return train_ds, val_ds\n",
    "\n",
    "\n",
    "def train_model(train_ds, val_ds):\n",
    "\n",
    "    data_augmentation = keras.Sequential(\n",
    "        [\n",
    "            layers.RandomFlip(\"horizontal\",\n",
    "                              input_shape=(HEIGHT,\n",
    "                                           WIDTH,\n",
    "                                           1)),\n",
    "            layers.RandomRotation(0.1),\n",
    "            layers.RandomZoom(0.1),\n",
    "        ]\n",
    "    )\n",
    "    num_classes = 3\n",
    "\n",
    "    model = Sequential([\n",
    "        data_augmentation,\n",
    "        layers.Rescaling(1. / 255),\n",
    "        layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(num_classes, name=\"outputs\")\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=EPOCHS\n",
    "    )\n",
    "\n",
    "\n",
    "    version = 1\n",
    "    while True:\n",
    "        model_file = \"models/model_{}.h5\".format(version)\n",
    "        if not os.path.exists(model_file):\n",
    "            break\n",
    "        version += 1\n",
    "\n",
    "    model.save(model_file)\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs_range = range(EPOCHS)\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 15\n",
    "HEIGHT = 60\n",
    "WIDTH = 60\n",
    "IMAGE_SHAPE = (HEIGHT, WIDTH)\n",
    "SEED = 42\n",
    "\n",
    "def train_and_save_model(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    train, val = load_images('../Dataset/multi_otsu', '../Dataset/validation_otsu')\n",
    "    train_model(train, val)\n",
    "\n",
    "\n",
    "with multiprocessing.Pool(processes=os.cpu_count()) as pool:\n",
    "    pool.map(train_and_save_model, range(123, 123 * 11, 123))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Workpackage: Model Evaluation\n",
    "\n",
    "Research Question:\n",
    "**What is the effect of using different evaluation metrics on the appearance of the model performance?**\n",
    "\n",
    "Research Answer:\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import os\n",
    "from math import sqrt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "\n",
    "def get_models(model_path):\n",
    "    models = []\n",
    "    for filename in os.listdir(model_path):\n",
    "        if filename.endswith(\".h5\"):\n",
    "            model = keras.models.load_model(os.path.join(model_path, filename))\n",
    "            models.append(model)\n",
    "    return models\n",
    "\n",
    "\n",
    "def predict_images(model, image_path):\n",
    "    test_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        image_path,\n",
    "        validation_split=None,\n",
    "        subset=None,\n",
    "        shuffle=False,\n",
    "        color_mode='grayscale',\n",
    "        image_size=IMAGE_SHAPE,\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "\n",
    "    predictions = model.predict(test_data)\n",
    "    return tf.argmax(predictions, axis=1)\n",
    "\n",
    "\n",
    "def predict_ensemble(ensemble_indexes, predictions, weights):\n",
    "    pred = []\n",
    "    for i in range(len(predictions[0])):\n",
    "        weighted_votes = np.zeros(np.max(predictions) + 1)\n",
    "        for j, instrument in enumerate(ensemble_indexes):\n",
    "            instrument_prediction = predictions[instrument][i]\n",
    "            weighted_votes[instrument_prediction] += weights[j]\n",
    "        pred.append(np.argmax(weighted_votes))\n",
    "    return pred\n",
    "\n",
    "def plotMetrics(truth, pred):\n",
    "    true_rock = truth.copy()\n",
    "    true_paper = truth.copy()\n",
    "    true_scissors = truth.copy()\n",
    "    pred_rock = pred.copy()\n",
    "    pred_paper = pred.copy()\n",
    "    pred_scissors = pred.copy()\n",
    "    for i in range(len(true_rock)):\n",
    "        if true_rock[i] != 0:\n",
    "            true_rock[i] = 1\n",
    "    for i in range(len(true_paper)):\n",
    "        if true_paper[i] != 1:\n",
    "            true_paper[i] = 0\n",
    "    for i in range(len(true_scissors)):\n",
    "        if true_scissors[i] != 2:\n",
    "            true_scissors[i] = 1\n",
    "    for i in range(len(pred_rock)):\n",
    "        if pred_rock[i] != 0:\n",
    "            pred_rock[i] = 1\n",
    "    for i in range(len(pred_paper)):\n",
    "        if pred_paper[i] != 1:\n",
    "            pred_paper[i] = 0\n",
    "    for i in range(len(pred_scissors)):\n",
    "        if pred_scissors[i] != 2:\n",
    "            pred_scissors[i] = 1\n",
    "    matrix = confusion_matrix(y_true=truth,y_pred=pred)\n",
    "\n",
    "    #fp,tp,tn,fn for each class\n",
    "    tp_rock = matrix[0, 0]\n",
    "    tp_paper = matrix[1, 1]\n",
    "    tp_scissors = matrix[2, 2]\n",
    "    tp_total = tp_rock + tp_paper + tp_scissors\n",
    "\n",
    "    tn_rock = np.sum(matrix) - (tp_rock + matrix[0, 1] + matrix[0, 2])\n",
    "    tn_paper = np.sum(matrix) - (tp_paper + matrix[1, 0] + matrix[1, 2])\n",
    "    tn_scissors = np.sum(matrix) - (tp_scissors + matrix[2, 0] + matrix[2, 1])\n",
    "\n",
    "    fp_rock = matrix[0, 1] + matrix[0, 2]\n",
    "    fp_paper = matrix[1, 0] + matrix[1, 2]\n",
    "    fp_scissors = matrix[2, 0] + matrix[2, 1]\n",
    "\n",
    "    fn_rock = matrix[1, 0] + matrix[2, 0]\n",
    "    fn_paper = matrix[0, 1] + matrix[2, 1]\n",
    "    fn_scissors = matrix[0, 2] + matrix[1, 2]\n",
    "\n",
    "    #confusion matrix for each class\n",
    "    confusion_matrix_rock = np.array([[tn_rock, fp_rock], [fn_rock, tp_rock]])\n",
    "    confusion_matrix_paper = np.array([[tn_paper, fp_paper], [fn_paper, tp_paper]])\n",
    "    confusion_matrix_scissors = np.array([[tn_scissors, fp_scissors], [fn_scissors, tp_scissors]])\n",
    "\n",
    "    labels = ['rock', 'paper', 'scissors']\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    image = ax.imshow(matrix, cmap='Blues')\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            ax.text(j, i, matrix[i][j], ha='center', va='center', color='black')\n",
    "\n",
    "    ax.set_xticks(range(3))\n",
    "    ax.set_yticks(range(3))\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_yticklabels(labels)\n",
    "    ax.set_title('Confusion Matrix')\n",
    "    fig.colorbar(image)\n",
    "    plt.show()\n",
    "\n",
    "    accuracy_rock = accuracy_score(y_true=true_rock,y_pred=pred_rock)\n",
    "    accuracy_paper = accuracy_score(y_true=true_paper,y_pred=pred_paper)\n",
    "    accuracy_scissors = accuracy_score(y_true=true_scissors,y_pred=pred_scissors)\n",
    "    accuracy_total = accuracy_score(y_true=truth,y_pred=pred)\n",
    "    accuracy_array = [accuracy_rock,accuracy_paper,accuracy_scissors]\n",
    "    print(accuracy_rock)\n",
    "    print(accuracy_paper)\n",
    "    print(accuracy_scissors)\n",
    "    print(accuracy_total)\n",
    "    precision_array, recall_array, f1_array, _ = precision_recall_fscore_support(y_true=truth,y_pred=pred)\n",
    "    precision_rock = precision_array[0]\n",
    "    precision_paper = precision_array[1]\n",
    "    precision_scissors = precision_array[2]\n",
    "\n",
    "    recall_rock = recall_array[0]\n",
    "    recall_paper = recall_array[1]\n",
    "    recall_scissors = recall_array[2]\n",
    "\n",
    "    f1_rock = f1_array[0]\n",
    "    f1_paper = f1_array[1]\n",
    "    f1_scissors = f1_array[2]\n",
    "\n",
    "    mcc_rock = calculate_mcc(tp_rock,tn_rock,fp_rock,fn_rock)\n",
    "    mcc_paper = calculate_mcc(tp_paper,tn_paper,fp_paper,fn_paper)\n",
    "    mcc_scissors = calculate_mcc(tp_scissors,tn_scissors,fp_scissors,fn_scissors)\n",
    "    mcc_array = [mcc_rock,mcc_paper,mcc_scissors]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(15,5))\n",
    "    x = np.arange(3)\n",
    "    ax.bar(x - 0.15, accuracy_array, 0.15, label='Accuracy',color='#FFFB7A')\n",
    "    ax.bar(x, precision_array, 0.15, label='Precision',color='#65EBBB')\n",
    "    ax.bar(x + 0.15, f1_array, 0.15, label='F1 score',color='#E365EB')\n",
    "    ax.bar(x+0.3, recall_array, 0.15, label='Recall',color='#7398FF')\n",
    "    ax.bar(x + 0.45, mcc_array, 0.15, label='MCC',color='#FF9966')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(['rock', 'paper', 'scissors'])\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    return\n",
    "def draw_graphs(matrix):\n",
    "    labels = ['rock', 'paper', 'scissors']\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    image = ax.imshow(matrix, cmap='Blues')\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            ax.text(j, i, matrix[i][j], ha='center', va='center', color='black')\n",
    "\n",
    "    ax.set_xticks(range(3))\n",
    "    ax.set_yticks(range(3))\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_yticklabels(labels)\n",
    "    ax.set_title('Confusion Matrix')\n",
    "    fig.colorbar(image)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def calculate_mcc(tp, tn, fp, fn):\n",
    "    try:\n",
    "        return (tp * tn - fp * fn) / sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "    except Exception as e:\n",
    "        return 0\n",
    "\n",
    "def get_best_model(mcc_total,accuracy_total,f1_total):\n",
    "    max_mcc_value = np.amax(mcc_total)\n",
    "    max_mcc_index = mcc_total.index(max_mcc_value)\n",
    "    print(\"the best mcc is: \" + str(max_mcc_value) + \" on model_\" + str(max_mcc_index + 1) + \".h5\")\n",
    "    max_acc_value = np.amax(accuracy_total)\n",
    "    max_acc_index = accuracy_total.index(max_acc_value)\n",
    "    print(\"the best accuracy is: \" + str(max_acc_value) + \" on model_\" + str(max_acc_index + 1) + \".h5\")\n",
    "    max_f1_value = np.amax(f1_total)\n",
    "    max_f1_index = f1_total.index(max_f1_value)\n",
    "    print(\"the best f1 is: \" + str(max_f1_value) + \" on model_\" + str(max_f1_index + 1) + \".h5\")\n",
    "    return max_mcc_index\n",
    "\n",
    "def get_best_ensemble(mcc_total):\n",
    "    sorted = mcc_total.copy()\n",
    "    sorted.sort()\n",
    "    max_mcc = sorted[-5:]\n",
    "    ensemble_indexes = []\n",
    "    for value in max_mcc:\n",
    "        ensemble_indexes.append(mcc_total.index(value))\n",
    "    return ensemble_indexes\n",
    "\n",
    "def get_matrix_values(truth, prediction):\n",
    "    matrix = confusion_matrix(y_true=truth, y_pred=prediction)\n",
    "\n",
    "    # fp,tp,tn,fn for each class\n",
    "    tp_rock = matrix[0, 0]\n",
    "    tp_paper = matrix[1, 1]\n",
    "    tp_scissors = matrix[2, 2]\n",
    "    tp_total = tp_rock + tp_paper + tp_scissors\n",
    "\n",
    "    tn_rock = np.sum(matrix) - (tp_rock + matrix[0, 1] + matrix[0, 2])\n",
    "    tn_paper = np.sum(matrix) - (tp_paper + matrix[1, 0] + matrix[1, 2])\n",
    "    tn_scissors = np.sum(matrix) - (tp_scissors + matrix[2, 0] + matrix[2, 1])\n",
    "\n",
    "    fp_rock = matrix[0, 1] + matrix[0, 2]\n",
    "    fp_paper = matrix[1, 0] + matrix[1, 2]\n",
    "    fp_scissors = matrix[2, 0] + matrix[2, 1]\n",
    "\n",
    "    fn_rock = matrix[1, 0] + matrix[2, 0]\n",
    "    fn_paper = matrix[0, 1] + matrix[2, 1]\n",
    "    fn_scissors = matrix[0, 2] + matrix[1, 2]\n",
    "\n",
    "    # confusion matrix for each class\n",
    "    confusion_matrix_rock = np.array([[tn_rock, fp_rock], [fn_rock, tp_rock]])\n",
    "    confusion_matrix_paper = np.array([[tn_paper, fp_paper], [fn_paper, tp_paper]])\n",
    "    confusion_matrix_scissors = np.array([[tn_scissors, fp_scissors], [fn_scissors, tp_scissors]])\n",
    "\n",
    "    return matrix, [tp_rock,tp_paper,tp_scissors],[tn_rock,tn_paper,tn_scissors],[fp_rock,fp_paper,fp_scissors],[fn_rock,fn_paper,fn_scissors]\n",
    "\n",
    "\n",
    "def calculate_best_model():\n",
    "    num_paper = len([f for f in os.listdir(TEST_DATA_PATH+'/paper') if os.path.isfile(os.path.join(TEST_DATA_PATH+'/paper', f))])\n",
    "    num_rock = len([f for f in os.listdir(TEST_DATA_PATH + '/rock') if\n",
    "                     os.path.isfile(os.path.join(TEST_DATA_PATH + '/rock', f))])\n",
    "    num_scissors = len([f for f in os.listdir(TEST_DATA_PATH + '/scissors') if\n",
    "                     os.path.isfile(os.path.join(TEST_DATA_PATH + '/scissors', f))])\n",
    "    truth = np.concatenate([np.full((num_paper),0),np.full((num_rock),1),np.full((num_scissors-1),2)])\n",
    "    models = get_models('models/otsu_models60x60')\n",
    "    predictions = []\n",
    "    mcc_rock = []\n",
    "    mcc_paper = []\n",
    "    mcc_scissors = []\n",
    "    mcc_total = []\n",
    "    f1_rock = []\n",
    "    f1_paper = []\n",
    "    f1_scissors = []\n",
    "    f1_total = []\n",
    "    precision_rock = []\n",
    "    precision_paper = []\n",
    "    precision_scissors = []\n",
    "    recall_rock = []\n",
    "    recall_paper = []\n",
    "    recall_scissors = []\n",
    "    accuracy_rock = []\n",
    "    accuracy_paper = []\n",
    "    accuracy_scissors = []\n",
    "    accuracy_total = []\n",
    "    for model in models:\n",
    "        prediction = predict_images(model, TEST_DATA_PATH)\n",
    "        predictions.append(prediction)\n",
    "        matrix, tp, tn, fp, fn = get_matrix_values(truth, prediction)\n",
    "        mcc_rock.append(calculate_mcc(tp=tp[0], tn=tn[0], fp=fp[0], fn=fn[0]))\n",
    "        mcc_paper.append(calculate_mcc(tp=tp[1], tn=tn[1], fp=fp[1], fn=fn[1]))\n",
    "        mcc_scissors.append(calculate_mcc(tp=tp[2], tn=tn[2], fp=fp[2], fn=fn[2]))\n",
    "        accuracy_total.append(accuracy_score(y_true=truth, y_pred=prediction))\n",
    "        precision_array, recall_array, f1_array, _ = precision_recall_fscore_support(y_true=truth, y_pred=prediction)\n",
    "        precision_rock.append(precision_array[0])\n",
    "        precision_paper.append(precision_array[1])\n",
    "        precision_scissors.append(precision_array[2])\n",
    "\n",
    "        recall_rock.append(recall_array[0])\n",
    "        recall_paper.append(recall_array[1])\n",
    "        recall_scissors.append(recall_array[2])\n",
    "\n",
    "        f1_rock.append(f1_array[0])\n",
    "        f1_paper.append(f1_array[1])\n",
    "        f1_scissors.append(f1_array[2])\n",
    "\n",
    "    for i in range(0, len(mcc_rock)):\n",
    "        mcc_total.append((mcc_rock[i] + mcc_paper[i] + mcc_scissors[i])/3)\n",
    "        f1_total.append((f1_rock[i] + f1_paper[i] + f1_scissors[i])/3)\n",
    "\n",
    "    best_index = get_best_model(mcc_total, accuracy_total, f1_total)\n",
    "    plotMetrics(truth, predictions[best_index].numpy())\n",
    "\n",
    "    best_ensemble = get_best_ensemble(mcc_total)\n",
    "    total = 0\n",
    "    weights = []\n",
    "    for instrument in best_ensemble:\n",
    "        total += mcc_total[instrument]\n",
    "    for i in range(len(best_ensemble)):\n",
    "        weights.append(mcc_total[i]/total)\n",
    "    ensemble_prediction = predict_ensemble(best_ensemble, predictions, weights)\n",
    "    plotMetrics(truth, ensemble_prediction)\n",
    "    matrix, tp, tn, fp, fn = get_matrix_values(truth, ensemble_prediction)\n",
    "    mcc_rock_ensemble =calculate_mcc(tp=tp[0], tn=tn[0], fp=fp[0], fn=fn[0])\n",
    "    mcc_paper_ensemble = calculate_mcc(tp=tp[1], tn=tn[1], fp=fp[1], fn=fn[1])\n",
    "    mcc_scissors_ensemble = calculate_mcc(tp=tp[2], tn=tn[2], fp=fp[2], fn=fn[2])\n",
    "    mcc_total_ensemble =(mcc_rock_ensemble + mcc_paper_ensemble + mcc_scissors_ensemble) / 3\n",
    "    print(\"MCC ensemble: \"+str(mcc_total_ensemble))\n",
    "\n",
    "\n",
    "\n",
    "IMAGE_SHAPE = (60, 60)\n",
    "BATCH_SIZE = 32\n",
    "TEST_DATA_PATH = '../Dataset/testing_otsu'\n",
    "\n",
    "calculate_best_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}